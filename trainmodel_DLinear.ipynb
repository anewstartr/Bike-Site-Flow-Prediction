{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99664d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader,RandomSampler,SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "# import optuna\n",
    "from torch.nn import functional\n",
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa6e955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753, 3312, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = np.load('D:/myfiles/project/bike_prediction/feature_data/tcn_data_3d.npy')\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79753ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【站点数量，序列长度，特征数量】\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, his_datas, his_label, output_size, feature_size, seq_num, time_of_day):\n",
    "        self.his_datas = his_datas  #【N，1080，X】\n",
    "        # self.sta_datas = sta_datas  #【N，26，Y】\n",
    "        self.his_label = his_label  #【N，1080，1】\n",
    "        self.output_size = output_size  # 输出长度24\n",
    "        self.feature_size = feature_size  # 卷积塔时序特征数量\n",
    "        # self.static_feature_size = static_feature_size  # 特征塔天粒度/静态特征数量\n",
    "        self.seq_num = seq_num  # 窗口大小\n",
    "        self.time_of_day = time_of_day  # 每天24小时\n",
    "         \n",
    "        self.site_num = his_datas.shape[0]  # 站点数量\n",
    "        self.time_num = his_datas.shape[1] // time_of_day  - (seq_num + 3) # 单个站点的样本数量：26-15=11个样本\n",
    "        self.sample_num = self.time_num * self.site_num  # 总样本数量：32*1080=3w\n",
    "        # print(his_datas.shape)\n",
    "        print('单个样本数量：', self.time_num)\n",
    "        print('站点数量：', self.site_num)\n",
    "        print('总样本数量：', self.sample_num)\n",
    "        print(\"a\", his_datas.shape, his_label.shape)\n",
    "        \n",
    "    def __getitem__(self, index): # 0-3w\n",
    "        # 是第几个样本？\n",
    "        cls_indx, time_indx = divmod(index, self.time_num)\n",
    "        start_index = time_indx * self.time_of_day\n",
    "        end_index = (time_indx + self.seq_num) * self.time_of_day\n",
    "        # [站点,小时粒度序列,小时粒度特征]\n",
    "        tmp_data = self.his_datas[cls_indx, start_index:end_index, 0:self.feature_size].astype(float)  # [0, 14*24, time_feature_size]\n",
    "        sample_time_data = torch.tensor(tmp_data, dtype=torch.float32)\n",
    "        # [站点,天粒度序列,天粒度特征]\n",
    "        # static_data = self.sta_datas[cls_indx, static_index:static_index+1, 0:self.static_feature_size].astype(float)  # [0, 1, time_feature_size]\n",
    "        # sample_static_data = torch.tensor(static_data, dtype=torch.float32)\n",
    "        # [站点,序列,1]\n",
    "        label_start = end_index   #理想情况，不加self.time_of_day，即t日结束时预测t+1日的流量\n",
    "        label_end = label_start + self.output_size\n",
    "        target_label = self.his_label[cls_indx, label_start:label_end, 0:1].astype(float)\n",
    "        sample_labels = torch.tensor(target_label, dtype=torch.float32)\n",
    "        \n",
    "        return sample_time_data, sample_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sample_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d472ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(all_data):  # 56天\n",
    "    tmp_data_info = np.array(all_data)\n",
    "    # sta_data_info = np.array(sta_data)\n",
    "    # 当前总时长为138天，4.15-8.30\n",
    "    train_start_idx = 0\n",
    "    train_end_idx = 76 * 24 \n",
    "    val_start_idx = 76 * 24\n",
    "    val_end_idx = 107 * 24 \n",
    "    test_start_idx = 107 * 24\n",
    "    test_end_idx = 138 * 24 \n",
    "    # train_start_sta_idx = 0\n",
    "    # train_end_sta_idx = 18\n",
    "    # val_end_sta_idx = 22\n",
    "    # test_end_sta_idx = 26\n",
    "    \n",
    "#     train_start_idx = 0\n",
    "#     train_end_idx = 38 * 24  # 9\n",
    "#     val_start_idx = (38 - 30) * 24  # 13使用14，14使用15\n",
    "#     val_end_idx = 42 * 24  # 4\n",
    "#     test_start_idx = (42 - 30) * 24\n",
    "#     test_end_idx = 49 * 24  # 7\n",
    "    \n",
    "    train_data = tmp_data_info[:, train_start_idx:train_end_idx, :]  # 所有特征\n",
    "    # train_data_sta = sta_data_info[:, train_start_sta_idx:train_end_sta_idx, :]\n",
    "    train_label = tmp_data_info[:, train_start_idx:train_end_idx, 0:1]\n",
    "    val_data = tmp_data_info[:, val_start_idx:val_end_idx, :]\n",
    "    # val_data_sta = sta_data_info[:, train_end_sta_idx:val_end_sta_idx, :]    \n",
    "    val_label = tmp_data_info[:, val_start_idx:val_end_idx, 0:1]\n",
    "    test_data = tmp_data_info[:, test_start_idx:test_end_idx, :]\n",
    "    # test_data_sta = sta_data_info[:, val_end_sta_idx:test_end_sta_idx, :]  \n",
    "    test_label = tmp_data_info[:, test_start_idx:test_end_idx, 0:1]\n",
    "    return train_data, train_label, val_data, val_label, test_data, test_label\n",
    "    # return train_data, train_data_sta, train_label, val_data, val_data_sta, val_label, test_data, test_data_sta, test_label\n",
    "\n",
    "\n",
    "\n",
    "def load_data(all_data, batch_size):\n",
    "    train_data, train_label, val_data, val_label, test_data, test_label = train_test_split(all_data)\n",
    "    \n",
    "    # 创建数据集\n",
    "    train_dataset = MyDataset(his_datas=train_data, his_label=train_label, \n",
    "                             output_size=24, feature_size=8, seq_num=7, time_of_day=24)\n",
    "    \n",
    "    # 创建训练样本索引\n",
    "    n_train = len(train_dataset)\n",
    "    indices = list(range(n_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split_point = int(n_train * 0.4)\n",
    "    train_indices = indices[:split_point]\n",
    "    \n",
    "    # 创建采样器\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        sampler=train_sampler,\n",
    "        pin_memory=True  # 加速GPU数据传输\n",
    "    )\n",
    "    \n",
    "    # 验证和测试集保持完整\n",
    "    val_dataset = MyDataset(his_datas=val_data, his_label=val_label, \n",
    "                           output_size=24, feature_size=8, seq_num=7, time_of_day=24)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_dataset = MyDataset(his_datas=test_data, his_label=test_label, \n",
    "                             output_size=24, feature_size=8, seq_num=7, time_of_day=24)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92b2bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dlinear模型：简易baseline\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] =str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.daterministic = True\n",
    "\n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        # print(front.shape, x.shape, end.shape)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        \n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        # print(x.shape)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "\n",
    "class DLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    Decomposition-Linear\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len, pred_len, individual, channels):\n",
    "        super(DLinear, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        # Decompsition Kernel Size\n",
    "        kernel_size = 49\n",
    "        self.decompsition = series_decomp(kernel_size)\n",
    "        self.individual = individual\n",
    "        self.channels = channels\n",
    "\n",
    "        if self.individual:\n",
    "            self.Linear_Seasonal = nn.ModuleList()\n",
    "            self.Linear_Trend = nn.ModuleList()\n",
    "            \n",
    "            for i in range(self.channels):\n",
    "                self.Linear_Seasonal.append(nn.Linear(self.seq_len,self.pred_len))\n",
    "                self.Linear_Trend.append(nn.Linear(self.seq_len,self.pred_len))\n",
    "\n",
    "                # Use this two lines if you want to visualize the weights\n",
    "                self.Linear_Seasonal[i].weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "                self.Linear_Trend[i].weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "        else:\n",
    "            self.Linear_Seasonal = nn.Linear(self.seq_len,self.pred_len)\n",
    "            self.Linear_Trend = nn.Linear(self.seq_len,self.pred_len)\n",
    "            \n",
    "            # Use this two lines if you want to visualize the weights\n",
    "            self.Linear_Seasonal.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "            self.Linear_Trend.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Input length, Channel]\n",
    "        seasonal_init, trend_init = self.decompsition(x)\n",
    "        seasonal_init, trend_init = seasonal_init.permute(0,2,1), trend_init.permute(0,2,1)\n",
    "        if self.individual:\n",
    "            seasonal_output = torch.zeros([seasonal_init.size(0),seasonal_init.size(1),self.pred_len],dtype=seasonal_init.dtype).to(seasonal_init.device)\n",
    "            trend_output = torch.zeros([trend_init.size(0),trend_init.size(1),self.pred_len],dtype=trend_init.dtype).to(trend_init.device)\n",
    "            for i in range(self.channels):\n",
    "                seasonal_output[:,i,:] = self.Linear_Seasonal[i](seasonal_init[:,i,:])\n",
    "                trend_output[:,i,:] = self.Linear_Trend[i](trend_init[:,i,:])\n",
    "        else:\n",
    "            seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "            trend_output = self.Linear_Trend(trend_init)\n",
    "\n",
    "        x = seasonal_output + trend_output\n",
    "        x = x.permute(0,2,1) # to [Batch, Output length, Channel]\n",
    "\n",
    "        return x[:,:,0]\n",
    "\n",
    "class PeakHuberLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PeakHuberLoss, self).__init__()\n",
    "    def forward(self, y_pred, y_true, delta = 5):\n",
    "        # y_pred: [B, 24, 1]; y_true: [B, 24, 1]\n",
    "        # 标准化形状，确保可广播\n",
    "        if y_pred.ndim == 2:\n",
    "            y_pred = y_pred.unsqueeze(-1)\n",
    "        if y_true.ndim == 2:\n",
    "            y_true = y_true.unsqueeze(-1)\n",
    "        error = y_true - y_pred\n",
    "        peak_mask = (y_true >= 5)\n",
    "        # 让空集合时保持为张量而不是 Python float\n",
    "        if torch.any(peak_mask):\n",
    "            peak_err = error[peak_mask]\n",
    "            peak_loss = torch.where(torch.abs(peak_err) <= delta,\n",
    "                                    0.5 * peak_err**2,\n",
    "                                    delta * (torch.abs(peak_err) - 0.5 * delta)).mean()\n",
    "        else:\n",
    "            peak_loss = torch.zeros((), device=error.device)\n",
    "        non_peak_mask = ~peak_mask\n",
    "        if torch.any(non_peak_mask):\n",
    "            non_peak_err = error[non_peak_mask]\n",
    "            non_peak_loss = torch.abs(non_peak_err).mean()\n",
    "        else:\n",
    "            non_peak_loss = torch.zeros((), device=error.device)\n",
    "        total_loss = peak_loss * 2 + non_peak_loss\n",
    "        return total_loss  # 返回单个标量张量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feec6007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "(753, 3312, 8)\n",
      "单个样本数量： 66\n",
      "站点数量： 753\n",
      "总样本数量： 49698\n",
      "a (753, 1824, 8) (753, 1824, 1)\n",
      "单个样本数量： 21\n",
      "站点数量： 753\n",
      "总样本数量： 15813\n",
      "a (753, 744, 8) (753, 744, 1)\n",
      "单个样本数量： 21\n",
      "站点数量： 753\n",
      "总样本数量： 15813\n",
      "a (753, 744, 8) (753, 744, 1)\n"
     ]
    }
   ],
   "source": [
    "setup_seed(12345)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "output_sizes = 24\n",
    "\n",
    "# device = 'cpu'\n",
    "print('device:', device)\n",
    "print(all_data.shape)\n",
    "# print(static_all_data.shape)\n",
    "\n",
    "# 加载数据\n",
    "train_dataloader, val_dataloader, test_dataloader = load_data(all_data[:, :, :], 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5998d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, val_dataloader, model_save_path, epochs=50, lr=0.001):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # 初始化模型\n",
    "    model = DLinear(seq_len=168, pred_len=24, individual=True, channels=8).to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # 损失函数和优化器\n",
    "    criterion = PeakHuberLoss().to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "    \n",
    "    # 早停参数\n",
    "    min_epochs = 10\n",
    "    max_es_epoch = 10\n",
    "    min_val_loss = float('inf')\n",
    "    es_cnt = 0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for (seq, label) in train_dataloader:\n",
    "            seq = seq.to(device)\n",
    "            label = label.to(device)\n",
    "            if label.shape[0] != 1024:\n",
    "                continue\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(seq)\n",
    "            loss = criterion(y_pred, label)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss_avg = sum(train_losses) / len(train_losses) if train_losses else 0\n",
    "\n",
    "        # 每2个epoch进行验证\n",
    "        if epoch % 2 == 0:\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            with torch.no_grad():\n",
    "                for (seq, label) in val_dataloader:\n",
    "                    seq = seq.to(device)\n",
    "                    label = label.to(device)\n",
    "                    if label.shape[0] != 1024:\n",
    "                        continue\n",
    "                    y_pred = model(seq)\n",
    "                    loss = criterion(y_pred, label)\n",
    "                    val_losses.append(loss.item())\n",
    "\n",
    "            val_loss_avg = sum(val_losses) / len(val_losses) if val_losses else 0\n",
    "            print(f'Epoch {epoch:03d} train_loss {train_loss_avg:.6f} val_loss {val_loss_avg:.6f}')\n",
    "\n",
    "            if val_loss_avg < min_val_loss:\n",
    "                min_val_loss = val_loss_avg\n",
    "                es_cnt = 0\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "                print(f'保存最佳模型，验证损失: {val_loss_avg:.6f}')\n",
    "            else:\n",
    "                es_cnt += 1\n",
    "                if es_cnt >= max_es_epoch and epoch >= min_epochs:\n",
    "                    print('触发早停机制！')\n",
    "                    break\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def test(test_dataloader, model_save_path):\n",
    "    \"\"\"测试模型，返回预测值和真实值\"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # 加载模型\n",
    "    model = DLinear(seq_len=168, pred_len=24, individual=True, channels=8).to(device)\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    \n",
    "    criterion = PeakHuberLoss().to(device)\n",
    "    \n",
    "    # 初始化存储\n",
    "    test_losses = []\n",
    "    true_values = []\n",
    "    pred_values = []\n",
    "    \n",
    "    # 测试循环\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_time_data, test_labels in test_dataloader:\n",
    "            test_time_data = test_time_data.to(device)\n",
    "            test_labels = test_labels.to(device)\n",
    "            if test_labels.shape[0] != 1024:\n",
    "                continue\n",
    "            # 前向传播\n",
    "            test_forecasts = model(test_time_data)\n",
    "            \n",
    "            # 计算损失\n",
    "            test_loss = criterion(test_forecasts, test_labels)\n",
    "            test_losses.append(test_loss.item())\n",
    "            \n",
    "            # 存储真实值和预测值\n",
    "            true_values.append(test_labels.cpu().numpy())\n",
    "            pred_values.append(test_forecasts.cpu().numpy())\n",
    "    \n",
    "    # 计算平均损失\n",
    "    test_loss_avg = sum(test_losses) / len(test_losses) if test_losses else 0\n",
    "    print(f'Test Loss: {test_loss_avg:.6f}')\n",
    "    \n",
    "    return pred_values, true_values\n",
    "\n",
    "\n",
    "def evaluate_metrics(pred_values, true_values):\n",
    "    \"\"\"评估测试集的 MSE / MAPE / WMAPE（仅统计真值>5的样本）\"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    if not pred_values or not true_values:\n",
    "        print(\"pred_values / true_values 为空，请先运行测试循环。\")\n",
    "        return\n",
    "    \n",
    "    y_pred = np.concatenate(pred_values, axis=0)  # [N, 24, 1]\n",
    "    y_true = np.concatenate(true_values, axis=0)  # [N, 24, 1]\n",
    "    # print(y_pred.shape)\n",
    "    # 去掉最后一个特征维度\n",
    "    # y_pred = y_pred.squeeze(-1)  # [N, 24]\n",
    "    # y_true = y_true.squeeze(-1)  # [N, 24]\n",
    "\n",
    "    def compute_metrics_gt5(y_true_slice, y_pred_slice, gt_min=5):\n",
    "        \"\"\"仅在真值>gt_min的样本上计算指标\"\"\"\n",
    "        mask = y_true_slice > gt_min\n",
    "        if not np.any(mask):\n",
    "            return float('nan'), float('nan'), float('nan')\n",
    "        yt = y_true_slice[mask]\n",
    "        yp = y_pred_slice[mask]\n",
    "        mse = float(np.mean((yp - yt) ** 2))\n",
    "        mape = float(np.mean(np.abs((yp - yt) / yt)))\n",
    "        denom = float(np.sum(np.abs(yt)))\n",
    "        wmape = float(np.sum(np.abs(yp - yt)) / denom) if denom > 0 else float('nan')\n",
    "        return mse, mape, wmape\n",
    "\n",
    "    # 定义时段索引\n",
    "    morning_idx = np.array([7, 8, 9])\n",
    "    evening_idx = np.array([18, 19, 20])\n",
    "    all_idx = np.arange(24)\n",
    "\n",
    "    # 早峰（仅真值>5）\n",
    "    mse_morning, mape_morning, wmape_morning = compute_metrics_gt5(\n",
    "        y_true[:, morning_idx].reshape(-1), y_pred[:, morning_idx].reshape(-1)\n",
    "    )\n",
    "    # 晚峰（仅真值>5）\n",
    "    mse_evening, mape_evening, wmape_evening = compute_metrics_gt5(\n",
    "        y_true[:, evening_idx].reshape(-1), y_pred[:, evening_idx].reshape(-1)\n",
    "    )\n",
    "    # 全天（仅真值>5）\n",
    "    mse_all, mape_all, wmape_all = compute_metrics_gt5(\n",
    "        y_true[:, all_idx].reshape(-1), y_pred[:, all_idx].reshape(-1)\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Test Metrics (y_true > 5 only) ===\")\n",
    "    print(f\"Morning 7-9   -> MSE: {mse_morning:.4f}, MAPE: {mape_morning:.4f}, WMAPE: {wmape_morning:.4f}\")\n",
    "    print(f\"Evening 18-20 -> MSE: {mse_evening:.4f}, MAPE: {mape_evening:.4f}, WMAPE: {wmape_evening:.4f}\")\n",
    "    print(f\"All-day 0-23  -> MSE: {mse_all:.4f}, MAPE: {mape_all:.4f}, WMAPE: {wmape_all:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'morning': {'mse': mse_morning, 'mape': mape_morning, 'wmape': wmape_morning},\n",
    "        'evening': {'mse': mse_evening, 'mape': mape_evening, 'wmape': wmape_evening},\n",
    "        'all_day': {'mse': mse_all, 'mape': mape_all, 'wmape': wmape_all}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e35d31cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:01<00:58,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 train_loss 54.712150 val_loss 24.123800\n",
      "保存最佳模型，验证损失: 24.123800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:02<00:42,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 train_loss 39.876983 val_loss 20.588317\n",
      "保存最佳模型，验证损失: 20.588317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:04<00:35,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 train_loss 36.843408 val_loss 19.375315\n",
      "保存最佳模型，验证损失: 19.375315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:05<00:34,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 train_loss 35.596587 val_loss 19.148305\n",
      "保存最佳模型，验证损失: 19.148305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:07<00:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 train_loss 35.045219 val_loss 18.769744\n",
      "保存最佳模型，验证损失: 18.769744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:09<00:33,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 train_loss 34.328458 val_loss 18.801849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:10<00:32,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 train_loss 33.659941 val_loss 18.479641\n",
      "保存最佳模型，验证损失: 18.479641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:12<00:32,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 train_loss 33.020373 val_loss 18.457349\n",
      "保存最佳模型，验证损失: 18.457349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:14<00:30,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 train_loss 32.857467 val_loss 18.611853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:16<00:29,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 train_loss 32.223962 val_loss 18.147063\n",
      "保存最佳模型，验证损失: 18.147063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:18<00:27,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 train_loss 32.164516 val_loss 18.090262\n",
      "保存最佳模型，验证损失: 18.090262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:20<00:26,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022 train_loss 31.926340 val_loss 17.943350\n",
      "保存最佳模型，验证损失: 17.943350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:21<00:23,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 024 train_loss 31.334619 val_loss 17.774129\n",
      "保存最佳模型，验证损失: 17.774129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:23<00:22,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 026 train_loss 31.138503 val_loss 17.690513\n",
      "保存最佳模型，验证损失: 17.690513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [00:25<00:19,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 028 train_loss 30.752665 val_loss 17.867728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:27<00:18,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 030 train_loss 30.352147 val_loss 17.597933\n",
      "保存最佳模型，验证损失: 17.597933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:29<00:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 032 train_loss 30.805123 val_loss 17.611098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:30<00:14,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 034 train_loss 30.012267 val_loss 17.476837\n",
      "保存最佳模型，验证损失: 17.476837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [00:32<00:12,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 036 train_loss 30.140970 val_loss 17.698292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [00:34<00:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 038 train_loss 29.354023 val_loss 17.322534\n",
      "保存最佳模型，验证损失: 17.322534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [00:36<00:08,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 040 train_loss 29.044208 val_loss 17.015259\n",
      "保存最佳模型，验证损失: 17.015259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [00:38<00:06,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 042 train_loss 29.451089 val_loss 17.141240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [00:40<00:04,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 044 train_loss 29.018586 val_loss 16.893847\n",
      "保存最佳模型，验证损失: 16.893847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [00:41<00:02,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 046 train_loss 28.987665 val_loss 17.128441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [00:43<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 048 train_loss 28.393745 val_loss 16.791861\n",
      "保存最佳模型，验证损失: 16.791861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:44<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始测试...\n",
      "Test Loss: 17.816539\n",
      "15 15\n",
      "\n",
      "评估指标...\n",
      "\n",
      "=== Test Metrics (y_true > 5 only) ===\n",
      "Morning 7-9   -> MSE: 71.6610, MAPE: 0.5797, WMAPE: 0.5838\n",
      "Evening 18-20 -> MSE: 45.1358, MAPE: 0.5338, WMAPE: 0.5166\n",
      "All-day 0-23  -> MSE: 49.2837, MAPE: 0.4523, WMAPE: 0.4187\n"
     ]
    }
   ],
   "source": [
    "# 完整的训练、测试、评估流程\n",
    "\n",
    "# 1. 训练模型\n",
    "model_save_path = 'pred_model/net_divvy_DLinear_2.pth'\n",
    "print(\"开始训练...\")\n",
    "trained_model = train(train_dataloader, val_dataloader, model_save_path, epochs=50, lr=0.001)\n",
    "\n",
    "# 2. 测试模型\n",
    "print(\"\\n开始测试...\")\n",
    "pred_values, true_values = test(test_dataloader, model_save_path)\n",
    "print(len(pred_values), len(true_values))\n",
    "# 3. 评估指标\n",
    "print(\"\\n评估指标...\")\n",
    "metrics = evaluate_metrics(pred_values, true_values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikpred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
