{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99664d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.utils.data import Dataset, DataLoader,RandomSampler,SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "# import optuna\n",
    "from torch.nn import functional\n",
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fa6e955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753, 3312, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = np.load('D:/myfiles/project/bike_prediction/feature_data/tcn_data_3d.npy')\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79753ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【站点数量，序列长度，特征数量】\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, his_datas, his_label, output_size, feature_size, seq_num, time_of_day):\n",
    "        self.his_datas = his_datas  #【N，1080，X】\n",
    "        # self.sta_datas = sta_datas  #【N，26，Y】\n",
    "        self.his_label = his_label  #【N，1080，1】\n",
    "        self.output_size = output_size  # 输出长度24\n",
    "        self.feature_size = feature_size  # 卷积塔时序特征数量\n",
    "        # self.static_feature_size = static_feature_size  # 特征塔天粒度/静态特征数量\n",
    "        self.seq_num = seq_num  # 窗口大小\n",
    "        self.time_of_day = time_of_day  # 每天24小时\n",
    "         \n",
    "        self.site_num = his_datas.shape[0]  # 站点数量\n",
    "        self.time_num = his_datas.shape[1] // time_of_day  - (seq_num + 3) # 单个站点的样本数量：26-15=11个样本\n",
    "        self.sample_num = self.time_num * self.site_num  # 总样本数量：32*1080=3w\n",
    "        # print(his_datas.shape)\n",
    "        print('单个样本数量：', self.time_num)\n",
    "        print('站点数量：', self.site_num)\n",
    "        print('总样本数量：', self.sample_num)\n",
    "        print(\"a\", his_datas.shape, his_label.shape)\n",
    "        \n",
    "    def __getitem__(self, index): # 0-3w\n",
    "        # 是第几个样本？\n",
    "        cls_indx, time_indx = divmod(index, self.time_num)\n",
    "        start_index = time_indx * self.time_of_day\n",
    "        end_index = (time_indx + self.seq_num) * self.time_of_day\n",
    "        # [站点,小时粒度序列,小时粒度特征]\n",
    "        tmp_data = self.his_datas[cls_indx, start_index:end_index, 0:self.feature_size].astype(float)  # [0, 14*24, time_feature_size]\n",
    "        sample_time_data = torch.tensor(tmp_data, dtype=torch.float32)\n",
    "        # [站点,天粒度序列,天粒度特征]\n",
    "        # static_data = self.sta_datas[cls_indx, static_index:static_index+1, 0:self.static_feature_size].astype(float)  # [0, 1, time_feature_size]\n",
    "        # sample_static_data = torch.tensor(static_data, dtype=torch.float32)\n",
    "        # [站点,序列,1]\n",
    "        label_start = end_index   #理想情况，不加self.time_of_day，即t日结束时预测t+1日的流量\n",
    "        label_end = label_start + self.output_size\n",
    "        target_label = self.his_label[cls_indx, label_start:label_end, 0:1].astype(float)\n",
    "        sample_labels = torch.tensor(target_label, dtype=torch.float32)\n",
    "        \n",
    "        return sample_time_data, sample_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sample_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d472ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(all_data):  # 56天\n",
    "    tmp_data_info = np.array(all_data)\n",
    "    # sta_data_info = np.array(sta_data)\n",
    "    # 当前总时长为138天，4.15-8.30\n",
    "    train_start_idx = 0\n",
    "    train_end_idx = 76 * 24 \n",
    "    val_start_idx = 76 * 24\n",
    "    val_end_idx = 107 * 24 \n",
    "    test_start_idx = 107 * 24\n",
    "    test_end_idx = 138 * 24 \n",
    "    # train_start_sta_idx = 0\n",
    "    # train_end_sta_idx = 18\n",
    "    # val_end_sta_idx = 22\n",
    "    # test_end_sta_idx = 26\n",
    "    \n",
    "#     train_start_idx = 0\n",
    "#     train_end_idx = 38 * 24  # 9\n",
    "#     val_start_idx = (38 - 30) * 24  # 13使用14，14使用15\n",
    "#     val_end_idx = 42 * 24  # 4\n",
    "#     test_start_idx = (42 - 30) * 24\n",
    "#     test_end_idx = 49 * 24  # 7\n",
    "    \n",
    "    train_data = tmp_data_info[:, train_start_idx:train_end_idx, :]  # 所有特征\n",
    "    # train_data_sta = sta_data_info[:, train_start_sta_idx:train_end_sta_idx, :]\n",
    "    train_label = tmp_data_info[:, train_start_idx:train_end_idx, 0:1]\n",
    "    val_data = tmp_data_info[:, val_start_idx:val_end_idx, :]\n",
    "    # val_data_sta = sta_data_info[:, train_end_sta_idx:val_end_sta_idx, :]    \n",
    "    val_label = tmp_data_info[:, val_start_idx:val_end_idx, 0:1]\n",
    "    test_data = tmp_data_info[:, test_start_idx:test_end_idx, :]\n",
    "    # test_data_sta = sta_data_info[:, val_end_sta_idx:test_end_sta_idx, :]  \n",
    "    test_label = tmp_data_info[:, test_start_idx:test_end_idx, 0:1]\n",
    "    return train_data, train_label, val_data, val_label, test_data, test_label\n",
    "    # return train_data, train_data_sta, train_label, val_data, val_data_sta, val_label, test_data, test_data_sta, test_label\n",
    "\n",
    "\n",
    "\n",
    "def load_data(all_data, batch_size):\n",
    "    train_data, train_label, val_data, val_label, test_data, test_label = train_test_split(all_data)\n",
    "    \n",
    "    # 创建数据集\n",
    "    train_dataset = MyDataset(his_datas=train_data, his_label=train_label, \n",
    "                             output_size=24, feature_size=8, seq_num=7, time_of_day=24)\n",
    "    \n",
    "    # 创建训练样本索引\n",
    "    n_train = len(train_dataset)\n",
    "    indices = list(range(n_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split_point = int(n_train * 0.4)\n",
    "    train_indices = indices[:split_point]\n",
    "    \n",
    "    # 创建采样器\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        sampler=train_sampler,\n",
    "        pin_memory=True  # 加速GPU数据传输\n",
    "    )\n",
    "    \n",
    "    # 验证和测试集保持完整\n",
    "    val_dataset = MyDataset(his_datas=val_data, his_label=val_label, \n",
    "                           output_size=24, feature_size=8, seq_num=7, time_of_day=24)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_dataset = MyDataset(his_datas=test_data, his_label=test_label, \n",
    "                             output_size=24, feature_size=8, seq_num=7, time_of_day=24)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM时段输出模式1：线性映射最后时刻隐藏状态到输出\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] =str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.daterministic = True\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, batch_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.num_directions = 1 # 单向LSTM\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        batch_size, seq_len = input_seq.shape[0], input_seq.shape[1]\n",
    "        h_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        c_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        # output(batch_size, seq_len, num_directions * hidden_size)\n",
    "        output, _ = self.lstm(input_seq, (h_0, c_0)) # output(5, 30, 64)\n",
    "        pred = self.linear(output)  # (5, 30, 1)\n",
    "        pred = pred[:, -1, :]  # (5, 1)\n",
    "        return pred\n",
    "\n",
    "\n",
    "class PeakHuberLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PeakHuberLoss, self).__init__()\n",
    "    def forward(self, y_pred, y_true, delta = 5):\n",
    "        # y_pred: [B, 24, 1]; y_true: [B, 24, 1]\n",
    "        # 标准化形状，确保可广播\n",
    "        if y_pred.ndim == 2:\n",
    "            y_pred = y_pred.unsqueeze(-1)\n",
    "        if y_true.ndim == 2:\n",
    "            y_true = y_true.unsqueeze(-1)\n",
    "        error = y_true - y_pred\n",
    "        peak_mask = (y_true >= 5)\n",
    "        # 让空集合时保持为张量而不是 Python float\n",
    "        if torch.any(peak_mask):\n",
    "            peak_err = error[peak_mask]\n",
    "            peak_loss = torch.where(torch.abs(peak_err) <= delta,\n",
    "                                    0.5 * peak_err**2,\n",
    "                                    delta * (torch.abs(peak_err) - 0.5 * delta)).mean()\n",
    "        else:\n",
    "            peak_loss = torch.zeros((), device=error.device)\n",
    "        non_peak_mask = ~peak_mask\n",
    "        if torch.any(non_peak_mask):\n",
    "            non_peak_err = error[non_peak_mask]\n",
    "            non_peak_loss = torch.abs(non_peak_err).mean()\n",
    "        else:\n",
    "            non_peak_loss = torch.zeros((), device=error.device)\n",
    "        total_loss = peak_loss * 2 + non_peak_loss\n",
    "        return total_loss  # 返回单个标量张量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feec6007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "(753, 3312, 8)\n",
      "单个样本数量： 66\n",
      "站点数量： 753\n",
      "总样本数量： 49698\n",
      "a (753, 1824, 8) (753, 1824, 1)\n",
      "单个样本数量： 21\n",
      "站点数量： 753\n",
      "总样本数量： 15813\n",
      "a (753, 744, 8) (753, 744, 1)\n",
      "单个样本数量： 21\n",
      "站点数量： 753\n",
      "总样本数量： 15813\n",
      "a (753, 744, 8) (753, 744, 1)\n"
     ]
    }
   ],
   "source": [
    "#### setup_seed(12345)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "output_sizes = 24\n",
    "\n",
    "# device = 'cpu'\n",
    "print('device:', device)\n",
    "print(all_data.shape)\n",
    "# print(static_all_data.shape)\n",
    "\n",
    "# 加载数据\n",
    "train_dataloader, val_dataloader, test_dataloader = load_data(all_data[:, :, :], 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5998d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, val_dataloader, model_save_path, epochs=50, lr=0.001):\n",
    "    \"\"\"训练LSTM模型\"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # 初始化模型\n",
    "    model = LSTM(input_size=8, hidden_size=64, num_layers=2, output_size=24, batch_size=1024).to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # 损失函数和优化器\n",
    "    criterion = PeakHuberLoss().to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "    \n",
    "    # 早停参数\n",
    "    min_epochs = 10\n",
    "    max_es_epoch = 10\n",
    "    min_val_loss = float('inf')\n",
    "    es_cnt = 0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for (seq, label) in train_dataloader:\n",
    "            seq = seq.to(device)\n",
    "            label = label.to(device)\n",
    "            if label.shape[0] != 1024:\n",
    "                continue\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(seq)\n",
    "            loss = criterion(y_pred, label)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss_avg = sum(train_losses) / len(train_losses) if train_losses else 0\n",
    "\n",
    "        # 每2个epoch进行验证\n",
    "        if epoch % 2 == 0:\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            with torch.no_grad():\n",
    "                for (seq, label) in val_dataloader:\n",
    "                    seq = seq.to(device)\n",
    "                    label = label.to(device)\n",
    "                    if label.shape[0] != 1024:\n",
    "                        continue\n",
    "                    y_pred = model(seq)\n",
    "                    loss = criterion(y_pred, label)\n",
    "                    val_losses.append(loss.item())\n",
    "\n",
    "            val_loss_avg = sum(val_losses) / len(val_losses) if val_losses else 0\n",
    "            print(f'Epoch {epoch:03d} train_loss {train_loss_avg:.6f} val_loss {val_loss_avg:.6f}')\n",
    "\n",
    "            if val_loss_avg < min_val_loss:\n",
    "                min_val_loss = val_loss_avg\n",
    "                es_cnt = 0\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "                print(f'保存最佳模型，验证损失: {val_loss_avg:.6f}')\n",
    "            else:\n",
    "                es_cnt += 1\n",
    "                if es_cnt >= max_es_epoch and epoch >= min_epochs:\n",
    "                    print('触发早停机制！')\n",
    "                    break\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def test(test_dataloader, model_save_path):\n",
    "    \"\"\"测试LSTM模型，返回预测值和真实值\"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # 加载模型\n",
    "    model = LSTM(input_size=8, hidden_size=64, num_layers=2, output_size=24, batch_size=1024).to(device)\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    \n",
    "    criterion = PeakHuberLoss().to(device)\n",
    "    \n",
    "    # 初始化存储\n",
    "    test_losses = []\n",
    "    true_values = []\n",
    "    pred_values = []\n",
    "    \n",
    "    # 测试循环\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_time_data, test_labels in test_dataloader:\n",
    "            test_time_data = test_time_data.to(device)\n",
    "            test_labels = test_labels.to(device)\n",
    "            if test_labels.shape[0] != 1024:\n",
    "                continue\n",
    "            # 前向传播\n",
    "            test_forecasts = model(test_time_data)\n",
    "            \n",
    "            # 计算损失\n",
    "            test_loss = criterion(test_forecasts, test_labels)\n",
    "            test_losses.append(test_loss.item())\n",
    "            \n",
    "            # 存储真实值和预测值\n",
    "            true_values.append(test_labels.cpu().numpy())\n",
    "            pred_values.append(test_forecasts.cpu().numpy())\n",
    "    \n",
    "    # 计算平均损失\n",
    "    test_loss_avg = sum(test_losses) / len(test_losses) if test_losses else 0\n",
    "    print(f'Test Loss: {test_loss_avg:.6f}')\n",
    "    \n",
    "    return pred_values, true_values\n",
    "\n",
    "\n",
    "def evaluate_metrics(pred_values, true_values):\n",
    "    \"\"\"评估测试集的 MSE / MAPE / WMAPE（仅统计真值>5的样本）\"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    if not pred_values or not true_values:\n",
    "        print(\"pred_values / true_values 为空，请先运行测试循环。\")\n",
    "        return\n",
    "    \n",
    "    y_pred = np.concatenate(pred_values, axis=0)  # [N, 24, 1]\n",
    "    y_true = np.concatenate(true_values, axis=0)  # [N, 24, 1]\n",
    "    # print(y_pred.shape)\n",
    "    # 去掉最后一个特征维度\n",
    "    # y_pred = y_pred.squeeze(-1)  # [N, 24]\n",
    "    # y_true = y_true.squeeze(-1)  # [N, 24]\n",
    "\n",
    "    def compute_metrics_gt5(y_true_slice, y_pred_slice, gt_min=5):\n",
    "        \"\"\"仅在真值>gt_min的样本上计算指标\"\"\"\n",
    "        mask = y_true_slice > gt_min\n",
    "        if not np.any(mask):\n",
    "            return float('nan'), float('nan'), float('nan')\n",
    "        yt = y_true_slice[mask]\n",
    "        yp = y_pred_slice[mask]\n",
    "        mse = float(np.mean((yp - yt) ** 2))\n",
    "        mape = float(np.mean(np.abs((yp - yt) / yt)))\n",
    "        denom = float(np.sum(np.abs(yt)))\n",
    "        wmape = float(np.sum(np.abs(yp - yt)) / denom) if denom > 0 else float('nan')\n",
    "        return mse, mape, wmape\n",
    "\n",
    "    # 定义时段索引\n",
    "    morning_idx = np.array([7, 8, 9])\n",
    "    evening_idx = np.array([18, 19, 20])\n",
    "    all_idx = np.arange(24)\n",
    "\n",
    "    # 早峰（仅真值>5）\n",
    "    mse_morning, mape_morning, wmape_morning = compute_metrics_gt5(\n",
    "        y_true[:, morning_idx].reshape(-1), y_pred[:, morning_idx].reshape(-1)\n",
    "    )\n",
    "    # 晚峰（仅真值>5）\n",
    "    mse_evening, mape_evening, wmape_evening = compute_metrics_gt5(\n",
    "        y_true[:, evening_idx].reshape(-1), y_pred[:, evening_idx].reshape(-1)\n",
    "    )\n",
    "    # 全天（仅真值>5）\n",
    "    mse_all, mape_all, wmape_all = compute_metrics_gt5(\n",
    "        y_true[:, all_idx].reshape(-1), y_pred[:, all_idx].reshape(-1)\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Test Metrics (y_true > 5 only) ===\")\n",
    "    print(f\"Morning 7-9   -> MSE: {mse_morning:.4f}, MAPE: {mape_morning:.4f}, WMAPE: {wmape_morning:.4f}\")\n",
    "    print(f\"Evening 18-20 -> MSE: {mse_evening:.4f}, MAPE: {mape_evening:.4f}, WMAPE: {wmape_evening:.4f}\")\n",
    "    print(f\"All-day 0-23  -> MSE: {mse_all:.4f}, MAPE: {mape_all:.4f}, WMAPE: {wmape_all:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'morning': {'mse': mse_morning, 'mape': mape_morning, 'wmape': wmape_morning},\n",
    "        'evening': {'mse': mse_evening, 'mape': mape_evening, 'wmape': wmape_evening},\n",
    "        'all_day': {'mse': mse_all, 'mape': mape_all, 'wmape': wmape_all}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d31cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n",
      "\n",
      "开始测试...\n",
      "Test Loss: 14.638351\n",
      "15 15\n",
      "\n",
      "评估指标...\n",
      "\n",
      "=== Test Metrics (y_true > 5 only) ===\n",
      "Morning 7-9   -> MSE: 30.0968, MAPE: 0.2518, WMAPE: 0.3000\n",
      "Evening 18-20 -> MSE: 18.2220, MAPE: 0.2345, WMAPE: 0.2802\n",
      "All-day 0-23  -> MSE: 46.0842, MAPE: 0.2554, WMAPE: 0.2969\n",
      "Test Loss: 14.638351\n",
      "15 15\n",
      "\n",
      "评估指标...\n",
      "\n",
      "=== Test Metrics (y_true > 5 only) ===\n",
      "Morning 7-9   -> MSE: 30.0968, MAPE: 0.2518, WMAPE: 0.3000\n",
      "Evening 18-20 -> MSE: 18.2220, MAPE: 0.2345, WMAPE: 0.2802\n",
      "All-day 0-23  -> MSE: 46.0842, MAPE: 0.2554, WMAPE: 0.2969\n"
     ]
    }
   ],
   "source": [
    "# 完整的训练、测试、评估流程\n",
    "\n",
    "# 1. 训练模型\n",
    "model_save_path = 'pred_model/net_divvy_LSTM_1.pth'\n",
    "print(\"开始训练...\")\n",
    "# trained_model = train(train_dataloader, val_dataloader, model_save_path, epochs=50, lr=0.001)\n",
    "\n",
    "# 2. 测试模型\n",
    "print(\"\\n开始测试...\")\n",
    "pred_values, true_values = test(test_dataloader, model_save_path)\n",
    "print(len(pred_values), len(true_values))\n",
    "# 3. 评估指标\n",
    "print(\"\\n评估指标...\")\n",
    "metrics = evaluate_metrics(pred_values, true_values)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikpred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
