{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72e2001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.utils.data import Dataset, DataLoader,RandomSampler,SubsetRandomSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "# import optuna\n",
    "from torch.nn import functional\n",
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b15417a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753, 3312, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = np.load('D:/myfiles/project/bike_prediction/feature_data/tcn_data_3d.npy')\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5e1b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  9.,  17.,   8.,  12.,   2.,  13.,   6.,   0.],\n",
       "        [  9.,  19.,  10.,   9.,   2.,  10.,   6.,   1.],\n",
       "        [ 10.,  21.,  11.,  13.,   2.,  13.,   7.,   2.],\n",
       "        [ 10.,  22.,  12.,  11.,   1.,  12.,   6.,   3.],\n",
       "        [ 10.,  26.,  16.,   8.,  -1.,   9.,   8.,   4.],\n",
       "        [  2.,  27.,  25.,   0.,   0.,   7.,   3.,   5.],\n",
       "        [ -2.,  27.,  29.,  -5.,   0.,   6.,   1.,   6.],\n",
       "        [ -2.,  28.,  30.,  -6.,   0.,   0.,   1.,   7.],\n",
       "        [ -4.,  26.,  30., -12.,  -1.,  -6.,  -1.,   8.],\n",
       "        [-10.,  18.,  28., -14.,  -1., -10.,  -4.,   9.],\n",
       "        [ -8.,  19.,  27., -14.,  -2., -10.,  -4.,  10.],\n",
       "        [ -9.,  17.,  26., -14.,  -2., -10.,  -4.,  11.],\n",
       "        [-10.,  15.,  25., -12.,  -2.,  -9.,  -3.,  12.],\n",
       "        [-10.,  13.,  23., -10.,  -2.,  -6.,  -3.,  13.],\n",
       "        [-11.,  11.,  22., -14.,  -2.,  -9.,  -4.,  14.],\n",
       "        [-11.,  10.,  21., -12.,  -1.,  -8.,  -3.,  15.],\n",
       "        [-11.,   6.,  17.,  -9.,   1.,  -5.,  -5.,  16.],\n",
       "        [ -3.,   5.,   8.,  -1.,   0.,  -2.,   0.,  17.],\n",
       "        [  2.,   6.,   4.,   2.,   3.,   0.,   1.,  18.],\n",
       "        [  3.,   6.,   3.,   4.,   4.,   4.,   6.,  19.],\n",
       "        [  8.,   9.,   1.,   4.,  11.,   9.,  10.,  20.],\n",
       "        [ 14.,  17.,   3.,  10.,  13.,   9.,  11.,  21.],\n",
       "        [ 13.,  17.,   4.,   9.,  13.,   8.,  11.,  22.],\n",
       "        [ 12.,  17.,   5.,   9.,  13.,   9.,  11.,  23.],\n",
       "        [ 12.,  18.,   6.,   9.,  12.,  10.,  11.,   0.],\n",
       "        [ 12.,  19.,   7.,   9.,   9.,  10.,  10.,   1.],\n",
       "        [ 13.,  21.,   8.,  10.,  13.,  11.,   9.,   2.],\n",
       "        [ 13.,  22.,   9.,  10.,  11.,   8.,   5.,   3.],\n",
       "        [ 12.,  24.,  12.,  10.,   8.,   6.,   5.,   4.],\n",
       "        [  8.,  27.,  19.,   2.,   0.,   4.,   2.,   5.],\n",
       "        [  2.,  25.,  23.,  -2.,  -5.,   2.,  -1.,   6.],\n",
       "        [ -1.,  22.,  23.,  -2.,  -6.,   0.,  -6.,   7.],\n",
       "        [ -4.,  19.,  23.,  -4., -12.,  -6.,  -9.,   8.],\n",
       "        [-10.,  11.,  21., -10., -14.,  -5., -11.,   9.],\n",
       "        [-10.,  10.,  20.,  -8., -14.,  -5., -11.,  10.],\n",
       "        [ -8.,  10.,  18.,  -9., -14.,  -6., -11.,  11.],\n",
       "        [ -8.,   9.,  17., -10., -12.,  -7., -11.,  12.],\n",
       "        [ -8.,   8.,  16., -10., -10.,  -7.,  -9.,  13.],\n",
       "        [ -9.,   6.,  15., -11., -14.,  -8.,  -8.,  14.],\n",
       "        [ -9.,   5.,  14., -11., -12.,  -5.,  -4.,  15.],\n",
       "        [ -8.,   3.,  11., -11.,  -9.,  -3.,  -4.,  16.],\n",
       "        [ -4.,   0.,   4.,  -3.,  -1.,  -2.,  -1.,  17.],\n",
       "        [  1.,   1.,   0.,   2.,   2.,   0.,   2.,  18.],\n",
       "        [  4.,   4.,   0.,   3.,   4.,   0.,   4.,  19.],\n",
       "        [  8.,   8.,   0.,   8.,   4.,   3.,   5.,  20.],\n",
       "        [ 11.,  13.,   2.,  14.,  10.,   6.,   9.,  21.],\n",
       "        [ 11.,  13.,   2.,  13.,   9.,   8.,  10.,  22.],\n",
       "        [  9.,  14.,   5.,  12.,   9.,   8.,  11.,  23.],\n",
       "        [  9.,  15.,   6.,  12.,   9.,  10.,  10.,   0.],\n",
       "        [  8.,  15.,   7.,  12.,   9.,   9.,   8.,   1.],\n",
       "        [  9.,  18.,   9.,  13.,  10.,   7.,   8.,   2.],\n",
       "        [ 11.,  22.,  11.,  13.,  10.,   6.,   4.,   3.],\n",
       "        [  7.,  25.,  18.,  12.,  10.,   6.,   4.,   4.],\n",
       "        [  2.,  25.,  23.,   8.,   2.,   5.,   2.,   5.],\n",
       "        [  0.,  24.,  24.,   2.,  -2.,   0.,  -1.,   6.],\n",
       "        [ -4.,  21.,  25.,  -1.,  -2.,   0.,  -2.,   7.],\n",
       "        [ -8.,  17.,  25.,  -4.,  -4.,  -2.,  -4.,   8.],\n",
       "        [-11.,  12.,  23., -10., -10.,  -5.,  -7.,   9.],\n",
       "        [-11.,  12.,  23., -10.,  -8.,  -6.,  -8.,  10.],\n",
       "        [ -8.,  12.,  20.,  -8.,  -9.,  -6.,  -9.,  11.],\n",
       "        [ -8.,  11.,  19.,  -8., -10.,  -8.,  -8.,  12.],\n",
       "        [ -7.,  11.,  18.,  -8., -10.,  -8.,  -7.,  13.],\n",
       "        [ -8.,   8.,  16.,  -9., -11.,  -6.,  -7.,  14.],\n",
       "        [-10.,   4.,  14.,  -9., -11.,  -5.,  -3.,  15.],\n",
       "        [ -6.,   1.,   7.,  -8., -11.,  -5.,  -3.,  16.],\n",
       "        [ -1.,   1.,   2.,  -4.,  -3.,  -4.,  -1.,  17.],\n",
       "        [  1.,   2.,   1.,   1.,   2.,  -1.,   1.,  18.],\n",
       "        [  1.,   2.,   1.,   4.,   3.,   0.,   0.,  19.],\n",
       "        [  5.,   6.,   1.,   8.,   8.,   0.,   0.,  20.],\n",
       "        [  6.,   9.,   3.,  11.,  14.,   0.,   0.,  21.],\n",
       "        [  5.,  11.,   6.,  11.,  13.,   0.,   1.,  22.],\n",
       "        [  3.,  14.,  11.,   9.,  12.,  -2.,   1.,  23.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[1:2,0:72,0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c63c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【站点数量，序列长度，特征数量】\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, his_datas, his_label, output_size, feature_size, seq_num, time_of_day):\n",
    "        self.his_datas = his_datas  #【N，1080，X】\n",
    "        # self.sta_datas = sta_datas  #【N，26，Y】\n",
    "        self.his_label = his_label  #【N，1080，1】\n",
    "        self.output_size = output_size  # 输出长度24\n",
    "        self.feature_size = feature_size  # 卷积塔时序特征数量\n",
    "        # self.static_feature_size = static_feature_size  # 特征塔天粒度/静态特征数量\n",
    "        self.seq_num = seq_num  # 窗口大小\n",
    "        self.time_of_day = time_of_day  # 每天24小时\n",
    "         \n",
    "        self.site_num = his_datas.shape[0]  # 站点数量\n",
    "        self.time_num = his_datas.shape[1] // time_of_day  - (seq_num + 3) # 单个站点的样本数量：26-15=11个样本\n",
    "        self.sample_num = self.time_num * self.site_num  # 总样本数量：32*1080=3w\n",
    "        # print(his_datas.shape)\n",
    "        print('单个样本数量：', self.time_num)\n",
    "        print('站点数量：', self.site_num)\n",
    "        print('总样本数量：', self.sample_num)\n",
    "        print(\"a\", his_datas.shape, his_label.shape)\n",
    "        \n",
    "    def __getitem__(self, index): # 0-3w\n",
    "        # 是第几个样本？\n",
    "        cls_indx, time_indx = divmod(index, self.time_num)\n",
    "        start_index = time_indx * self.time_of_day\n",
    "        end_index = (time_indx + self.seq_num) * self.time_of_day\n",
    "        # [站点,小时粒度序列,小时粒度特征]\n",
    "        tmp_data = self.his_datas[cls_indx, start_index:end_index, 0:self.feature_size].astype(float)  # [0, 14*24, time_feature_size]\n",
    "        sample_time_data = torch.tensor(tmp_data, dtype=torch.float32)\n",
    "        # [站点,天粒度序列,天粒度特征]\n",
    "        # static_data = self.sta_datas[cls_indx, static_index:static_index+1, 0:self.static_feature_size].astype(float)  # [0, 1, time_feature_size]\n",
    "        # sample_static_data = torch.tensor(static_data, dtype=torch.float32)\n",
    "        # [站点,序列,1]\n",
    "        label_start = end_index\n",
    "        label_end = label_start + self.output_size\n",
    "        target_label = self.his_label[cls_indx, label_start:label_end, 0:1].astype(float)\n",
    "        sample_labels = torch.tensor(target_label, dtype=torch.float32)\n",
    "        \n",
    "        return sample_time_data, sample_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sample_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "505b001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(all_data):  # 56天\n",
    "    tmp_data_info = np.array(all_data)\n",
    "    # sta_data_info = np.array(sta_data)\n",
    "    # 当前总时长为138天，4.15-8.30\n",
    "    train_start_idx = 0\n",
    "    train_end_idx = 76 * 24 \n",
    "    val_start_idx = 76 * 24\n",
    "    val_end_idx = 107 * 24 \n",
    "    test_start_idx = 107 * 24\n",
    "    test_end_idx = 138 * 24 \n",
    "    # train_start_sta_idx = 0\n",
    "    # train_end_sta_idx = 18\n",
    "    # val_end_sta_idx = 22\n",
    "    # test_end_sta_idx = 26\n",
    "    \n",
    "#     train_start_idx = 0\n",
    "#     train_end_idx = 38 * 24  # 9\n",
    "#     val_start_idx = (38 - 30) * 24  # 13使用14，14使用15\n",
    "#     val_end_idx = 42 * 24  # 4\n",
    "#     test_start_idx = (42 - 30) * 24\n",
    "#     test_end_idx = 49 * 24  # 7\n",
    "    \n",
    "    train_data = tmp_data_info[:, train_start_idx:train_end_idx, :]  # 所有特征\n",
    "    # train_data_sta = sta_data_info[:, train_start_sta_idx:train_end_sta_idx, :]\n",
    "    train_label = tmp_data_info[:, train_start_idx:train_end_idx, 0:1]\n",
    "    val_data = tmp_data_info[:, val_start_idx:val_end_idx, :]\n",
    "    # val_data_sta = sta_data_info[:, train_end_sta_idx:val_end_sta_idx, :]    \n",
    "    val_label = tmp_data_info[:, val_start_idx:val_end_idx, 0:1]\n",
    "    test_data = tmp_data_info[:, test_start_idx:test_end_idx, :]\n",
    "    # test_data_sta = sta_data_info[:, val_end_sta_idx:test_end_sta_idx, :]  \n",
    "    test_label = tmp_data_info[:, test_start_idx:test_end_idx, 0:1]\n",
    "    return train_data, train_label, val_data, val_label, test_data, test_label\n",
    "    # return train_data, train_data_sta, train_label, val_data, val_data_sta, val_label, test_data, test_data_sta, test_label\n",
    "\n",
    "\n",
    "\n",
    "def load_data(all_data, batch_size):\n",
    "    train_data, train_label, val_data, val_label, test_data, test_label = train_test_split(all_data)\n",
    "    \n",
    "    # 创建数据集\n",
    "    train_dataset = MyDataset(his_datas=train_data, his_label=train_label, \n",
    "                             output_size=24, feature_size=8, seq_num=7, time_of_day=24)\n",
    "    \n",
    "    # 创建训练样本索引\n",
    "    n_train = len(train_dataset)\n",
    "    indices = list(range(n_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split_point = int(n_train * 0.4)\n",
    "    train_indices = indices[:split_point]\n",
    "    \n",
    "    # 创建采样器\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        sampler=train_sampler,\n",
    "        pin_memory=True  # 加速GPU数据传输\n",
    "    )\n",
    "    \n",
    "    # 验证和测试集保持完整\n",
    "    val_dataset = MyDataset(his_datas=val_data, his_label=val_label, \n",
    "                           output_size=24, feature_size=8, seq_num=7, time_of_day=24)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_dataset = MyDataset(his_datas=test_data, his_label=test_label, \n",
    "                             output_size=24, feature_size=8, seq_num=7, time_of_day=24)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader\n",
    "\n",
    "\n",
    "# def load_multitask_data(all_data, sta_data, batch_size, output_sizes={0: 24, 1: 24, 2: 24}):\n",
    "#     # 自定义collate函数处理多目标数据\n",
    "#     def multitask_collate(batch):\n",
    "#         time_data = torch.stack([item[0] for item in batch])\n",
    "#         static_data = torch.stack([item[1] for item in batch])\n",
    "#         labels = {}\n",
    "#         for target_idx in output_sizes.keys():\n",
    "#             labels[target_idx] = torch.stack([item[2][target_idx] for item in batch])\n",
    "#         return time_data, static_data, labels\n",
    "#     train_data, train_data_sta, train_label, val_data, val_data_sta, val_label, test_data, test_data_sta, test_label = train_test_split(all_data, sta_data)\n",
    "#     train_dataset = MyDataset(his_datas=train_data, sta_datas = train_data_sta, his_label=train_label, \n",
    "#                               output_sizes=output_sizes, time_feature_size=22, static_feature_size=7, seq_num=14, time_of_day=24)\n",
    "#     n_samples = len(train_dataset)\n",
    "#     indices = list(range(n_samples))\n",
    "#     # 随机选择50%的样本\n",
    "#     split = int(0.4 * n_samples)\n",
    "#     np.random.shuffle(indices)\n",
    "#     train_indices = indices[:split]  # 前50%作为本次训练样本\n",
    "#     # 创建采样器\n",
    "#     train_sampler = SubsetRandomSampler(train_indices)\n",
    "#     train_dataloader = DataLoader(\n",
    "#         train_dataset,\n",
    "#         batch_size=batch_size,\n",
    "#         sampler=train_sampler,\n",
    "#         collate_fn=multitask_collate\n",
    "#     )\n",
    "#     # train_rand_sampler = RandomSampler(train_dataset, replacement=False, num_samples=int(len(train_dataset)*0.3))\n",
    "#     # train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=False, sampler=train_rand_sampler) \n",
    "#     # train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True) \n",
    "      \n",
    "#     val_dataset = MyDataset(his_datas=val_data, sta_datas = val_data_sta, his_label=val_label,\n",
    "#                             output_sizes=output_sizes, time_feature_size=22, static_feature_size=7, seq_num=14, time_of_day=24)\n",
    "#     val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, collate_fn=multitask_collate)\n",
    "\n",
    "#     test_dataset = MyDataset(his_datas=test_data, sta_datas = test_data_sta, his_label=test_label,\n",
    "#                              output_sizes=output_sizes, time_feature_size=22, static_feature_size=7, seq_num=14, time_of_day=24)\n",
    "#     test_dataloader = DataLoader(test_dataset, batch_size = 4, shuffle=False, collate_fn=multitask_collate)\n",
    "\n",
    "#     return train_dataloader , val_dataloader, test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c44f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "def huber_loss(y_pred, y_true):\n",
    "    loss = torch.nn.SmoothL1Loss(reduction='mean',beta=5.0)(y_pred, y_true)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mse_loss(y_pred, y_true):\n",
    "    loss = torch.nn.MSELoss(reduction='mean')(y_pred, y_true)\n",
    "    return loss\n",
    "    \n",
    "\n",
    "def printbar():\n",
    "    t = datetime.datetime.now()\n",
    "    print('==========='*8 + str(t))\n",
    "\n",
    "\n",
    "import os\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] =str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.daterministic = True\n",
    "    \n",
    "\n",
    "# models/informer_full.py\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------\n",
    "# Positional / Temporal Embedding\n",
    "# ---------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=10000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)  # (max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (B, L, D) -> return (1, L, D)\n",
    "        return self.pe[:x.size(1)].unsqueeze(0).to(x.device)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple value embedding (linear) + positional encoding.\n",
    "    In full Informer they also use temporal embedding (time-of-day, day-of-week). \n",
    "    You can extend here if you have those features.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, d_model, max_len=10000):\n",
    "        super().__init__()\n",
    "        self.value_embedding = nn.Linear(input_dim, d_model)\n",
    "        self.position = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, L, input_dim)\n",
    "        x = self.value_embedding(x) + self.position(x)\n",
    "        return x  # (B, L, d_model)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# ProbSparse Attention (efficient attention) implementation\n",
    "# This is a simplified but working form of ProbSparse used in Informer.\n",
    "# ---------------------------\n",
    "def _get_topk_indices(scores, k):\n",
    "    # scores: (..., Lk)\n",
    "    # return top-k indices along last dim\n",
    "    _, idx = torch.topk(scores, k, dim=-1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "class ProbAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=False, factor=5, scale=None):\n",
    "        super().__init__()\n",
    "        self.mask_flag = mask_flag\n",
    "        self.factor = factor  # factor for sample size\n",
    "        self.scale = scale\n",
    "\n",
    "    def _prob_QK(self, Q, K):\n",
    "        # Q: (B, H, Lq, D), K: (B, H, Lk, D)\n",
    "        B, H, Lq, D = Q.shape\n",
    "        _, _, Lk, _ = K.shape\n",
    "\n",
    "        # sample u keys for each query where u = factor * ln(Lk)\n",
    "        u = max(1, min(Lk, int(self.factor * math.ceil(math.log(Lk + 1)))))  # sample size\n",
    "        # random sample index from keys\n",
    "        K_expand = K.unsqueeze(-3).expand(B, H, Lq, Lk, D)  # (B,H,Lq,Lk,D)\n",
    "\n",
    "        # choose sampled keys index\n",
    "        # compute Q * K_sample^T for sampled K\n",
    "        index_sample = torch.randint(0, Lk, (Lq, u), device=Q.device)  # (Lq, u)\n",
    "        # gather sampled K\n",
    "        K_sample = K[:, :, index_sample, :]  # (B, H, Lq, u, D)\n",
    "        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-1, -2)).squeeze(-2)  # (B,H,Lq,u)\n",
    "        M = Q_K_sample.max(-1)[0] - Q_K_sample.mean(-1)  # (B,H,Lq)\n",
    "        # select top queries\n",
    "        topk = max(1, int(self.factor * math.ceil(math.log(Lq + 1))))\n",
    "        topk_indices = _get_topk_indices(M, topk)  # (B,H,topk)\n",
    "        return topk_indices  # indexes of important queries\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        # Q,K,V: (B, H, L, D)\n",
    "        B, H, Lq, D = Q.shape\n",
    "        _, _, Lk, _ = K.shape\n",
    "\n",
    "        # compute full scores for small sequences, else ProbSparse\n",
    "        if Lk <= 64:\n",
    "            scores = torch.matmul(Q, K.transpose(-1, -2))  # (B,H,Lq,Lk)\n",
    "            if self.scale is not None:\n",
    "                scores = scores / math.sqrt(self.scale)\n",
    "            if self.mask_flag and attn_mask is not None:\n",
    "                scores.masked_fill_(attn_mask.unsqueeze(1).unsqueeze(2), -1e9)\n",
    "            attn = torch.softmax(scores, dim=-1)\n",
    "            out = torch.matmul(attn, V)\n",
    "            return out\n",
    "\n",
    "        # ProbSparse for large Lk\n",
    "        # 1) find important queries\n",
    "        topk_idx = self._prob_QK(Q, K)  # (B,H,topk)\n",
    "        # gather selected Q\n",
    "        # build full attention only for topk queries, other queries get approximate aggregated value\n",
    "        # compute full scores at topk positions\n",
    "        # we'll compute scores for topk queries across all keys then scatter back\n",
    "        # prepare indexing\n",
    "        B_idx = torch.arange(B, device=Q.device)[:, None, None]\n",
    "        H_idx = torch.arange(H, device=Q.device)[None, :, None]\n",
    "        tq = topk_idx  # (B,H,topk)\n",
    "\n",
    "        # gather Q_topk: (B,H,topk,D)\n",
    "        Q_topk = torch.gather(Q, 2, tq.unsqueeze(-1).expand(-1, -1, -1, D))\n",
    "        # compute scores_topk: (B,H,topk,Lk)\n",
    "        scores_topk = torch.matmul(Q_topk, K.transpose(-1, -2))\n",
    "        if self.scale is not None:\n",
    "            scores_topk = scores_topk / math.sqrt(self.scale)\n",
    "        if self.mask_flag and attn_mask is not None:\n",
    "            # mask broadcasting\n",
    "            scores_topk = scores_topk.masked_fill(attn_mask.unsqueeze(1).unsqueeze(2), -1e9)\n",
    "        attn_topk = torch.softmax(scores_topk, dim=-1)  # (B,H,topk,Lk)\n",
    "        out_topk = torch.matmul(attn_topk, V)  # (B,H,topk,D)\n",
    "\n",
    "        # now create output tensor and scatter out_topk to their positions\n",
    "        out = torch.zeros_like(Q, device=Q.device)  # (B,H,Lq,D)\n",
    "        out = out.scatter(2, tq.unsqueeze(-1).expand(-1, -1, -1, D), out_topk)\n",
    "        # For non-selected queries, approximate by aggregate of V (mean)\n",
    "        V_mean = V.mean(2, keepdim=True).expand(-1, -1, Lq, -1)  # (B,H,Lq,D)\n",
    "        out = out + V_mean * 0.0  # keep zeros elsewhere (we could add approximation)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# MultiHead wrapper\n",
    "# ---------------------------\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, attention):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        self.n_heads = n_heads\n",
    "        self.d_head = d_model // n_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.w_qs = nn.Linear(d_model, d_model)\n",
    "        self.w_ks = nn.Linear(d_model, d_model)\n",
    "        self.w_vs = nn.Linear(d_model, d_model)\n",
    "        self.proj = nn.Linear(d_model, d_model)\n",
    "        self.attention = attention\n",
    "\n",
    "    def forward(self, q, k, v, attn_mask=None):\n",
    "        # q,k,v: (B, L, D)\n",
    "        B, Lq, D = q.shape\n",
    "        _, Lk, _ = k.shape\n",
    "\n",
    "        q = self.w_qs(q).view(B, Lq, self.n_heads, self.d_head).transpose(1, 2)  # (B, H, Lq, d_head)\n",
    "        k = self.w_ks(k).view(B, Lk, self.n_heads, self.d_head).transpose(1, 2)\n",
    "        v = self.w_vs(v).view(B, Lk, self.n_heads, self.d_head).transpose(1, 2)\n",
    "\n",
    "        out = self.attention(q, k, v, attn_mask=attn_mask)  # (B, H, Lq, d_head)\n",
    "        out = out.transpose(1, 2).contiguous().view(B, Lq, self.d_model)\n",
    "        out = self.proj(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Encoder/DecoderLayer & stacks\n",
    "# ---------------------------\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, n_heads, ProbAttention(scale=d_model))\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # x: (B, L, D)\n",
    "        new_x = self.attn(x, x, x, attn_mask=attn_mask)\n",
    "        x = x + self.dropout(new_x)\n",
    "        x = self.norm1(x)\n",
    "        y = x.transpose(-1, -2)  # (B, D, L)\n",
    "        y = self.conv2(self.dropout(self.activation(self.conv1(y))))\n",
    "        y = y.transpose(-1, -2)  # (B, L, D)\n",
    "        x = x + self.dropout(y)\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, num_layers, distil=True):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([layer for _ in range(num_layers)])\n",
    "        self.distil = distil\n",
    "        if distil:\n",
    "            # 1D conv for down-sampling (like paper)\n",
    "            self.conv_layers = nn.ModuleList([nn.Conv1d(in_channels=layer.attn.d_model, out_channels=layer.attn.d_model, kernel_size=3, padding=1, stride=2) for _ in range(max(0, num_layers-1))])\n",
    "            self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # x: (B, L, D)\n",
    "        seqs = []\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x, attn_mask=attn_mask)\n",
    "            seqs.append(x)\n",
    "            # distillation between layers: downsample temporal dim\n",
    "            if self.distil and i < len(self.layers) - 1:\n",
    "                x = x.transpose(1, 2)  # (B, D, L)\n",
    "                x = self.activation(self.conv_layers[i](x))\n",
    "                x = x.transpose(1, 2)  # (B, L//2, D)\n",
    "        return x  # final memory (B, L', D)\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, n_heads, ProbAttention(scale=d_model, mask_flag=True))\n",
    "        self.cross_attn = MultiHeadAttention(d_model, n_heads, ProbAttention(scale=d_model))\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu\n",
    "\n",
    "    def forward(self, x, memory, self_mask=None, cross_mask=None):\n",
    "        x = x + self.dropout(self.self_attn(x, x, x, attn_mask=self_mask))\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.dropout(self.cross_attn(x, memory, memory, attn_mask=cross_mask))\n",
    "        x = self.norm2(x)\n",
    "        y = x.transpose(-1, -2)\n",
    "        y = self.conv2(self.dropout(self.activation(self.conv1(y))))\n",
    "        y = y.transpose(-1, -2)\n",
    "        x = x + self.dropout(y)\n",
    "        x = self.norm3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer, num_layers, projection):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([layer for _ in range(num_layers)])\n",
    "        self.projection = projection  # final linear to output dim\n",
    "\n",
    "    def forward(self, x, memory, self_mask=None, cross_mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, self_mask, cross_mask)\n",
    "        out = self.projection(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Informer model\n",
    "# ---------------------------\n",
    "class Informer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 enc_in, dec_in, c_out,\n",
    "                 seq_len=168, label_len=24, out_len=24,\n",
    "                 d_model=512, n_heads=8,\n",
    "                 e_layers=3, d_layers=2,\n",
    "                 d_ff=2048, dropout=0.05, distil=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.pred_len = out_len\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model)\n",
    "        self.dec_embedding = DataEmbedding(dec_in, d_model)\n",
    "\n",
    "        # Encoder\n",
    "        enc_layer = EncoderLayer(d_model, n_heads, d_ff=d_ff, dropout=dropout)\n",
    "        self.encoder = Encoder(enc_layer, e_layers, distil=distil)\n",
    "\n",
    "        # Decoder\n",
    "        dec_layer = DecoderLayer(d_model, n_heads, d_ff=d_ff, dropout=dropout)\n",
    "        # projection to single value\n",
    "        projection = nn.Linear(d_model, c_out)\n",
    "        self.decoder = Decoder(dec_layer, d_layers, projection)\n",
    "\n",
    "        # final projection if needed (already in decoder)\n",
    "        # self.projection = nn.Linear(d_model, c_out)\n",
    "\n",
    "    def forward(self, x_enc, x_dec, enc_mask=None, dec_mask=None):\n",
    "        \"\"\"\n",
    "        x_enc: (B, seq_len, enc_in)\n",
    "        x_dec: (B, label_len + pred_len, dec_in) -- or (B, label_len, dec_in) with zeros padded to pred_len\n",
    "        returns: (B, pred_len, c_out)\n",
    "        \"\"\"\n",
    "        # embedding\n",
    "        enc_out = self.enc_embedding(x_enc)  # (B, seq_len, d_model)\n",
    "        enc_out = self.encoder(enc_out, attn_mask=enc_mask)  # memory\n",
    "\n",
    "        dec_out = self.dec_embedding(x_dec)  # (B, label_len+pred_len, d_model)\n",
    "        out = self.decoder(dec_out, enc_out, self_mask=dec_mask, cross_mask=None)  # (B, label_len+pred_len, c_out)\n",
    "        # take the last pred_len steps as prediction\n",
    "        return out[:, -self.pred_len:, :]  # (B, pred_len, c_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "913ebf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeakHuberLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PeakHuberLoss, self).__init__()\n",
    "    def forward(self, y_pred, y_true, delta = 5):\n",
    "        # y_pred: [B, 24, 1]; y_true: [B, 24, 1]\n",
    "        # 标准化形状，确保可广播\n",
    "        if y_pred.ndim == 2:\n",
    "            y_pred = y_pred.unsqueeze(-1)\n",
    "        if y_true.ndim == 2:\n",
    "            y_true = y_true.unsqueeze(-1)\n",
    "        error = y_true - y_pred\n",
    "        peak_mask = (y_true >= 5)\n",
    "        # 让空集合时保持为张量而不是 Python float\n",
    "        if torch.any(peak_mask):\n",
    "            peak_err = error[peak_mask]\n",
    "            peak_loss = torch.where(torch.abs(peak_err) <= delta,\n",
    "                                    0.5 * peak_err**2,\n",
    "                                    delta * (torch.abs(peak_err) - 0.5 * delta)).mean()\n",
    "        else:\n",
    "            peak_loss = torch.zeros((), device=error.device)\n",
    "        non_peak_mask = ~peak_mask\n",
    "        if torch.any(non_peak_mask):\n",
    "            non_peak_err = error[non_peak_mask]\n",
    "            non_peak_loss = torch.abs(non_peak_err).mean()\n",
    "        else:\n",
    "            non_peak_loss = torch.zeros((), device=error.device)\n",
    "        total_loss = peak_loss * 2 + non_peak_loss\n",
    "        return total_loss  # 返回单个标量张量\n",
    "    \n",
    "class MultiTaskPHLoss(nn.Module):\n",
    "    def __init__(self, loss_weights=None):\n",
    "        super(MultiTaskPHLoss, self).__init__()\n",
    "        self.peakhuberloss = PeakHuberLoss()\n",
    "        self.loss_weights = loss_weights\n",
    "    \n",
    "    def forward(self, predictions, targets, delta = 5):\n",
    "        total_loss = 0\n",
    "        losses = {}\n",
    "        for scale, pred in predictions.items():\n",
    "            target = targets[scale]\n",
    "            scale_loss = self.peakhuberloss(pred, target, delta = delta)\n",
    "            weight = self.loss_weights[scale] if self.loss_weights else 1.0\n",
    "            weighted_loss = weight * scale_loss\n",
    "            losses[scale] = scale_loss.item()\n",
    "            total_loss += weighted_loss\n",
    "        return total_loss, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ed22de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "(753, 3312, 8)\n",
      "单个样本数量： 66\n",
      "站点数量： 753\n",
      "总样本数量： 49698\n",
      "a (753, 1824, 8) (753, 1824, 1)\n",
      "单个样本数量： 21\n",
      "站点数量： 753\n",
      "总样本数量： 15813\n",
      "a (753, 744, 8) (753, 744, 1)\n",
      "单个样本数量： 21\n",
      "站点数量： 753\n",
      "总样本数量： 15813\n",
      "a (753, 744, 8) (753, 744, 1)\n"
     ]
    }
   ],
   "source": [
    "setup_seed(12345)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "output_sizes = 24\n",
    "\n",
    "# device = 'cpu'\n",
    "print('device:', device)\n",
    "print(all_data.shape)\n",
    "# print(static_all_data.shape)\n",
    "\n",
    "# 加载数据\n",
    "train_dataloader, val_dataloader, test_dataloader = load_data(all_data[:, :, :], 1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c570a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_decoder_inputs(x_enc, y_true, label_len=24, pred_len=24, feature_index=0):\n",
    "    \"\"\"\n",
    "    Construct x_dec for Informer as in paper:\n",
    "    - take last `label_len` values of the target (from input sequence)\n",
    "    - append pred_len zeros for future steps\n",
    "    Args:\n",
    "      x_enc: (B, seq_len, feat_dim)  --> contains target in channel feature_index\n",
    "      y_true: (B, pred_len, 1)       --> ground truth for loss (only for training)\n",
    "    Return:\n",
    "      x_dec: (B, label_len + pred_len, dec_in)\n",
    "    Note: dec_in will be same as enc_in for simplicity.\n",
    "    \"\"\"\n",
    "    B, _, feat_dim = x_enc.shape\n",
    "    # last label_len targets from encoder input's target channel\n",
    "    last_y = x_enc[:, -label_len:, feature_index:feature_index+1].clone()  # (B,label_len,1)\n",
    "    # zeros for future\n",
    "    zeros = torch.zeros(B, pred_len, 1, device=x_enc.device)\n",
    "    x_dec = torch.cat([last_y, zeros], dim=1)  # (B, label_len + pred_len, 1)\n",
    "    # if your decoder expects full feature vector, you can pad zeros for other features:\n",
    "    if feat_dim > 1:\n",
    "        # replicate zeros for other features (or provide known future covariates)\n",
    "        pad = torch.zeros(B, label_len + pred_len, feat_dim - 1, device=x_enc.device)\n",
    "        x_dec = torch.cat([x_dec, pad], dim=-1)  # (B, label_len+pred_len, feat_dim)\n",
    "    return x_dec\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, DEVICE):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "    for x, y in loader:\n",
    "        x = x.float().to(DEVICE)  # (B, 168, feat)\n",
    "        y = y.float().to(DEVICE)  # (B, 24, 1)\n",
    "        x_dec = prepare_decoder_inputs(x, y, label_len=24, pred_len=24, feature_index=0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x, x_dec)  # (B, 24, 1)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        n += x.size(0)\n",
    "    return total_loss / n\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, DEVICE):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.float().to(DEVICE)\n",
    "            y = y.float().to(DEVICE)\n",
    "            x_dec = prepare_decoder_inputs(x, y, label_len=24, pred_len=24, feature_index=0)\n",
    "            pred = model(x, x_dec)  # (B,24,1)\n",
    "            loss = criterion(pred, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            n += x.size(0)\n",
    "            preds.append(pred.cpu().numpy())\n",
    "            trues.append(y.cpu().numpy())\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    trues = np.concatenate(trues, axis=0)\n",
    "    # compute MAE / RMSE\n",
    "    mae = np.mean(np.abs(preds - trues))\n",
    "    rmse = np.sqrt(np.mean((preds - trues) ** 2))\n",
    "    return total_loss / n, mae, rmse, preds, trues\n",
    "\n",
    "\n",
    "def evaluate_metrics(y_pred, y_true):\n",
    "    \"\"\"评估测试集的 MSE / MAPE / WMAPE（仅统计真值>5的样本）\"\"\"\n",
    "    \n",
    "    # y_pred = np.concatenate(y_pred, axis=0)  # [N, 24, 1]\n",
    "    # y_true = np.concatenate(y_true, axis=0)  # [N, 24, 1]\n",
    "    print(y_pred.shape)\n",
    "    # 去掉最后一个特征维度\n",
    "    y_pred = y_pred.squeeze(-1)  # [N, 24]\n",
    "    y_true = y_true.squeeze(-1)  # [N, 24]\n",
    "\n",
    "    def compute_metrics_gt5(y_true_slice, y_pred_slice, gt_min=5):\n",
    "        \"\"\"仅在真值>gt_min的样本上计算指标\"\"\"\n",
    "        mask = y_true_slice > gt_min\n",
    "        if not np.any(mask):\n",
    "            return float('nan'), float('nan'), float('nan')\n",
    "        yt = y_true_slice[mask]\n",
    "        yp = y_pred_slice[mask]\n",
    "        mse = float(np.mean((yp - yt) ** 2))\n",
    "        mape = float(np.mean(np.abs((yp - yt) / yt)))\n",
    "        denom = float(np.sum(np.abs(yt)))\n",
    "        wmape = float(np.sum(np.abs(yp - yt)) / denom) if denom > 0 else float('nan')\n",
    "        return mse, mape, wmape\n",
    "\n",
    "    # 定义时段索引\n",
    "    morning_idx = np.array([7, 8, 9])\n",
    "    evening_idx = np.array([18, 19, 20])\n",
    "    all_idx = np.arange(24)\n",
    "\n",
    "    # 早峰（仅真值>5）\n",
    "    mse_morning, mape_morning, wmape_morning = compute_metrics_gt5(\n",
    "        y_true[:, morning_idx].reshape(-1), y_pred[:, morning_idx].reshape(-1)\n",
    "    )\n",
    "    # 晚峰（仅真值>5）\n",
    "    mse_evening, mape_evening, wmape_evening = compute_metrics_gt5(\n",
    "        y_true[:, evening_idx].reshape(-1), y_pred[:, evening_idx].reshape(-1)\n",
    "    )\n",
    "    # 全天（仅真值>5）\n",
    "    mse_all, mape_all, wmape_all = compute_metrics_gt5(\n",
    "        y_true[:, all_idx].reshape(-1), y_pred[:, all_idx].reshape(-1)\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Test Metrics (y_true > 5 only) ===\")\n",
    "    print(f\"Morning 7-9   -> MSE: {mse_morning:.4f}, MAPE: {mape_morning:.4f}, WMAPE: {wmape_morning:.4f}\")\n",
    "    print(f\"Evening 18-20 -> MSE: {mse_evening:.4f}, MAPE: {mape_evening:.4f}, WMAPE: {wmape_evening:.4f}\")\n",
    "    print(f\"All-day 0-23  -> MSE: {mse_all:.4f}, MAPE: {mape_all:.4f}, WMAPE: {wmape_all:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'morning': {'mse': mse_morning, 'mape': mape_morning, 'wmape': wmape_morning},\n",
    "        'evening': {'mse': mse_evening, 'mape': mape_evening, 'wmape': wmape_evening},\n",
    "        'all_day': {'mse': mse_all, 'mape': mape_all, 'wmape': wmape_all}\n",
    "    }\n",
    "\n",
    "def main_train(all_data, batch_size=512, epochs=30, model_save=\"pred_model/net_divvy_informer_1.pth\"):\n",
    "    # prepare dataloaders (your function)\n",
    "    train_loader, val_loader, test_loader = load_data(all_data, batch_size=batch_size)\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    enc_in = 8  # your feature size\n",
    "    dec_in = 8\n",
    "    c_out = 1\n",
    "\n",
    "    model = Informer(\n",
    "        enc_in=enc_in, dec_in=dec_in, c_out=c_out,\n",
    "        seq_len=168, label_len=24, out_len=24,\n",
    "        d_model=256, n_heads=8, e_layers=3, d_layers=2, d_ff=1024, distil=True\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    criterion = PeakHuberLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "    best_val_loss = 1e9\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
    "        val_loss, val_mae, val_rmse, _, _ = evaluate(model, val_loader, criterion, DEVICE)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"[Epoch {epoch}] train_loss={train_loss:.6f} val_loss={val_loss:.6f} val_mae={val_mae:.6f} val_rmse={val_rmse:.6f}\")\n",
    "\n",
    "        # save best\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), model_save)\n",
    "            print(\"Saved best model.\")\n",
    "\n",
    "    # load best and test\n",
    "    model.load_state_dict(torch.load(model_save))\n",
    "    test_loss, test_mae, test_rmse, preds, trues = evaluate(model, test_loader, criterion, DEVICE)\n",
    "    print(f\"TEST: loss={test_loss:.6f} mae={test_mae:.6f} rmse={test_rmse:.6f}\")\n",
    "    evaluate_metrics(preds, trues)\n",
    "    # return model and results\n",
    "    return model, (preds, trues)\n",
    "\n",
    "# model, results = main_train(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef9e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: loss=55.015587 mae=4.080723 rmse=9.547833\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Informer(\n",
    "        enc_in=8, dec_in=8, c_out=1,\n",
    "        seq_len=168, label_len=24, out_len=24,\n",
    "        d_model=256, n_heads=8, e_layers=3, d_layers=2, d_ff=1024, distil=True\n",
    "    ).to(device)\n",
    "model.load_state_dict(torch.load(\"pred_model/net_divvy_informer_1.pth\"))\n",
    "criterion = PeakHuberLoss()\n",
    "test_loss, test_mae, test_rmse, preds, trues = evaluate(model, test_dataloader, criterion, device)\n",
    "print(f\"TEST: loss={test_loss:.6f} mae={test_mae:.6f} rmse={test_rmse:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8a43759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15813, 24, 1)\n",
      "\n",
      "=== Test Metrics (y_true > 5 only) ===\n",
      "Morning 7-9   -> MSE: 589.6521, MAPE: 0.2628, WMAPE: 0.4143\n",
      "Evening 18-20 -> MSE: 423.0138, MAPE: 0.2415, WMAPE: 0.3759\n",
      "All-day 0-23  -> MSE: 438.8655, MAPE: 0.2563, WMAPE: 0.3528\n",
      "(15813, 24, 1) (15813, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "evaluate_metrics(preds, trues)\n",
    "print(trues.shape,preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac282e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikpred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
